# # parsers/base_parser.py
# import asyncio
# import re
# from abc import ABC, abstractmethod
# import asyncpg
# import httpx

# def light_normalize(name: str) -> str:
#     """
#     Ð›ÐµÐ³ÐºÐ°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ: Ð¿Ñ€Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ Ðº Ð½Ð¸Ð¶Ð½ÐµÐ¼Ñƒ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ñƒ,
#     ÑƒÐ±Ð¸Ñ€Ð°ÐµÑ‚ Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸ÑŽ Ð¸ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹, Ð½Ð¾ Ð¡ÐžÐ¥Ð ÐÐÐ¯Ð•Ð¢ Ð¦Ð˜Ð¤Ð Ð«.
#     """
#     name = name.lower()
#     # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ð´ÐµÑ„Ð¸ÑÑ‹, Ð·Ð°Ð¿ÑÑ‚Ñ‹Ðµ Ð¸ ÑÐ»ÑÑˆÐ¸ Ð½Ð° Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹
#     name = re.sub(r'[-,\/]', ' ', name)
#     # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹, ÐºÑ€Ð¾Ð¼Ðµ Ð±ÑƒÐºÐ², Ñ†Ð¸Ñ„Ñ€ Ð¸ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð²
#     name = re.sub(r'[^a-zÐ°-Ñ0-9\s]', '', name)
#     # Ð¡Ñ…Ð»Ð¾Ð¿Ñ‹Ð²Ð°ÐµÐ¼ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð² Ð¾Ð´Ð¸Ð½
#     return ' '.join(name.split())
    
# class BaseParser(ABC):
#     """ÐÐ±ÑÑ‚Ñ€Ð°ÐºÑ‚Ð½Ñ‹Ð¹ 'ÑÐºÐµÐ»ÐµÑ‚' Ð´Ð»Ñ Ð²ÑÐµÑ… Ð¿Ð°Ñ€ÑÐµÑ€Ð¾Ð²."""
#     def __init__(self, session: httpx.AsyncClient, db_pool: asyncpg.Pool):
#         self.session = session
#         self.db_pool = db_pool

#     async def fetch_html(self, url: str) -> str | None:
#         try:
#             await asyncio.sleep(0.5)
#             response = await self.session.get(url, timeout=20, follow_redirects=True)
#             response.raise_for_status()
#             return response.text
#         except httpx.RequestError as e:
#             print(f"ðŸš« ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {url}: {e}")
#             return None

#     @abstractmethod
#     async def get_pharmacy_id(self) -> int:
#         """ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐµÑ€ Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑƒÐ¼ÐµÑ‚ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð°Ñ‚ÑŒ ID ÑÐ²Ð¾ÐµÐ¹ Ð°Ð¿Ñ‚ÐµÐºÐ¸ Ð² Ð‘Ð”."""
#         pass
import asyncio
import re
from abc import ABC
import asyncpg
import httpx
from datetime import datetime
import random
import json
import aiofiles # For async file operations

# light_normalize function remains the same...
def light_normalize(name: str) -> str:
    # ...
    name = name.lower()
    name = re.sub(r'[-,\/]', ' ', name)
    name = re.sub(r'[^a-zÐ°-Ñ0-9\s]', '', name)
    return ' '.join(name.split())

class BaseParser(ABC):
    """Abstract base class for all parsers."""
    def __init__(self, session: httpx.AsyncClient, db_pool: asyncpg.Pool = None):
        self.base_url = 'https://gosapteka18.ru'
        self.session = session
        self.db_pool = db_pool
        # Lock to prevent race conditions when writing to the log file
        self.log_lock = asyncio.Lock()

    async def fetch_html(self, url: str, timeout: int = 20) -> str | None:
        try:
            # Increased delay slightly for more stability
            await asyncio.sleep(random.uniform(0.5, 1.5))
            response = await self.session.get(url, timeout=timeout)
            response.raise_for_status()
            return response.text
        except httpx.RequestError as e:
            # The print statement remains for real-time feedback
            print(f"ðŸš« Download error {url}: {str(e)}")
            return None
        except httpx.HTTPStatusError as e:
            print(f"ðŸš« Status error {e.response.status_code} for {url}: {str(e)}")
            return None

    async def log_error(self, url: str, breadcrumbs: list[str], error: str):
        """Asynchronously logs a failed URL and its context to a JSON file."""
        log_filename = f"log_error_{datetime.now().strftime('%Y-%m-%d')}.json"
        new_entry = {"url": url, "breadcrumbs": breadcrumbs, "error": error}

        async with self.log_lock: # Ensure only one task writes to the file at a time
            try:
                # Try to read existing data
                async with aiofiles.open(log_filename, mode='r', encoding='utf-8') as f:
                    content = await f.read()
                    data = json.loads(content)
            except (FileNotFoundError, json.JSONDecodeError):
                # If file doesn't exist or is empty/corrupt, start with an empty list
                data = []

            # Append new error and write back
            data.append(new_entry)
            async with aiofiles.open(log_filename, mode='w', encoding='utf-8') as f:
                await f.write(json.dumps(data, ensure_ascii=False, indent=2))