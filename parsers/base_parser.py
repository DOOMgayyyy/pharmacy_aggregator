# parsers/base_parser.py
import asyncio
import re
from abc import ABC, abstractmethod
import asyncpg
import httpx

def normalize_name(name: str) -> str:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è."""
    name = name.lower()
    patterns_to_remove = [
        r'\d+\s*(–º–≥|–º–ª|—à—Ç|–¥–æ–∑|–≥|—Å–º|–º–∫–≥)', r'‚Ññ\d+',
        r'(—Ç–∞–±|–∫–∞–ø—Å|—Ä-—Ä|–º–∞–∑—å|–≥–µ–ª—å|–∫—Ä–µ–º|–ø–æ—Ä|—Å—É–ø–ø|–∞–º–ø|—Å–ø—Ä–µ–π)',
        r'(–ø/–æ|–ø/–ø/–æ|—à–∏–ø|–∂–µ–≤–∞—Ç|–¥–∏—Å–ø–µ—Ä–≥)', r'(\(.*\)|\[.*\])'
    ]
    for pattern in patterns_to_remove:
        name = re.sub(pattern, ' ', name, flags=re.IGNORECASE)
    return ' '.join(name.split())

class BaseParser(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π '—Å–∫–µ–ª–µ—Ç' –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤."""
    def __init__(self, session: httpx.AsyncClient, db_pool: asyncpg.Pool):
        self.session = session
        self.db_pool = db_pool

    async def fetch_html(self, url: str) -> str | None:
        try:
            await asyncio.sleep(0.5)
            response = await self.session.get(url, timeout=20, follow_redirects=True)
            response.raise_for_status()
            return response.text
        except httpx.RequestError as e:
            print(f"üö´ –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return None

    @abstractmethod
    async def get_pharmacy_id(self) -> int:
        """–ö–∞–∂–¥—ã–π –ø–∞—Ä—Å–µ—Ä –¥–æ–ª–∂–µ–Ω —É–º–µ—Ç—å –ø–æ–ª—É—á–∞—Ç—å ID —Å–≤–æ–µ–π –∞–ø—Ç–µ–∫–∏ –≤ –ë–î."""
        pass