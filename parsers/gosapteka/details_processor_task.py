# parsers/gosapteka/details_processor_task.py
import asyncio
import os
import re
import json
from urllib.parse import urljoin

import asyncpg
import httpx
from bs4 import BeautifulSoup, Tag

# –ò–ó–ú–ï–ù–ï–ù–û: –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–º–µ–Ω
from ..base_parser import normalize_name
from config import DB_CONFIG, URLS_DIR, CONCURRENCY_LIMIT

class ProductProcessor:
    def __init__(self, session: httpx.AsyncClient, db_pool: asyncpg.Pool):
        self.base_url = 'https://gosapteka18.ru'
        self.session = session
        self.db_pool = db_pool
        self.price_regexes = [
            re.compile(r'product-card__price-value[^>]*>([\d\s,]+)'),
            re.compile(r'"price"\s*:\s*"(\d+\.?\d*)"'),
            re.compile(r'itemprop="price"[^>]+content="(\d+\.?\d*)"')
        ]
        self.pharmacy_name = "–ì–æ—Å–∞–ø—Ç–µ–∫–∞ 18"

    async def fetch_html(self, url: str) -> str | None:
        try:
            await asyncio.sleep(0.5)
            response = await self.session.get(url, timeout=20)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"üö´ –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return None

    def _get_title(self, soup: BeautifulSoup) -> str:
        # –í–∞—à —Å–µ–ª–µ–∫—Ç–æ—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        tag = soup.select_one('h1.title.headline-main__title.product-card__title, h1.product-card__title')
        return tag.get_text(strip=True) if tag else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"

    def _get_image(self, soup: BeautifulSoup) -> str:
        tag = soup.select_one('img.product-card__picture-view-img')
        return urljoin(self.base_url, tag['src']) if tag and 'src' in tag.attrs else ""

    def _get_description(self, soup: BeautifulSoup) -> str:
        block = soup.select_one('div.product-card__description')
        if not block: return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–ø–∏—Å–∞–Ω–∏—è –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∞—è, –æ—Å—Ç–∞–≤–ª—è–µ–º –µ–µ
        sections = {h.get_text(strip=True): " ".join([s.get_text(" ", strip=True) for s in h.find_next_siblings() if s.name != 'h4' and isinstance(s, Tag)]) for h in block.find_all('h4')}
        return "\n\n".join([f"{k}:\n{v}" for k, v in sections.items()]) if sections else (block.get_text(" ", strip=True) or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

    def _get_price(self, html: str) -> float | None:
        for regex in self.price_regexes:
            if match := regex.search(html):
                price_str = match.group(1).replace(' ', '').replace(',', '.')
                return float(price_str)
        return None

    async def save_data(self, data: dict):
        async with self.db_pool.acquire() as conn, conn.transaction():
            # –®–∞–≥ 1: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            await conn.execute("INSERT INTO medicine_types (name) VALUES ($1) ON CONFLICT (name) DO NOTHING", data['type_name'])
            type_id = await conn.fetchval("SELECT id FROM medicine_types WHERE name = $1", data['type_name'])

            # –ò–ó–ú–ï–ù–ï–ù–û: –®–∞–≥ 2: –í—Å—Ç–∞–≤–ª—è–µ–º `normalized_name` –≤ —Ç–∞–±–ª–∏—Ü—É medicines
            medicine_id = await conn.fetchval("""
                INSERT INTO medicines (name, normalized_name, description, image_url, type_id)
                VALUES ($1, $2, $3, $4, $5)
                ON CONFLICT (name) DO UPDATE SET
                    description = EXCLUDED.description,
                    image_url = EXCLUDED.image_url,
                    type_id = EXCLUDED.type_id,
                    normalized_name = EXCLUDED.normalized_name
                RETURNING id;
            """, data['name'], data['normalized_name'], data['description'], data['image_url'], type_id)

            # –®–∞–≥ 3: –ê–ø—Ç–µ–∫–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            pharmacy_id = await conn.fetchval("SELECT id FROM pharmacies WHERE address = $1", self.base_url) or await conn.fetchval("INSERT INTO pharmacies (name, address) VALUES ($1, $2) RETURNING id", self.pharmacy_name, self.base_url)

            # –ò–ó–ú–ï–ù–ï–ù–û: –®–∞–≥ 4: –£–±–∏—Ä–∞–µ–º `quantity` –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            await conn.execute("""
                INSERT INTO pharmacy_prices (pharmacy_id, medicine_id, price)
                VALUES ($1, $2, $3)
                ON CONFLICT (pharmacy_id, medicine_id) DO UPDATE SET
                    price = EXCLUDED.price,
                    last_updated = NOW();
            """, pharmacy_id, medicine_id, data['price'])


    async def process_product(self, product_url: str, category_name: str):
        print(f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞: {product_url}")
        html = await self.fetch_html(product_url)
        if not html: return

        soup = BeautifulSoup(html, 'html.parser')
        title = self._get_title(soup)
        if title == "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è": return

        price = self._get_price(html)
        if price is None: return
        
        # –ò–ó–ú–ï–ù–ï–ù–û: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º `normalized_name` –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        normalized = normalize_name(title)

        product_data = {
            'name': title,
            'normalized_name': normalized, # –î–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ —Å–ª–æ–≤–∞—Ä—å
            'description': self._get_description(soup),
            'image_url': self._get_image(soup),
            'price': price,
            'type_name': category_name or "–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"
        }

        await self.save_data(product_data)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {title} ‚Äî {price} —Ä—É–±.")


async def process_details_from_files():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç—Ç–æ–≥–æ –º–æ–¥—É–ª—è: —á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª—ã –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É."""
    if not os.path.exists(URLS_DIR) or not os.listdir(URLS_DIR):
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è '{URLS_DIR}' –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä —Å—Å—ã–ª–æ–∫.")
        return

    db_pool = None
    try:
        db_pool = await asyncpg.create_pool(**DB_CONFIG)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    async with httpx.AsyncClient(headers=headers, follow_redirects=True) as session:
        processor = ProductProcessor(session, db_pool)
        tasks = []

        print(f"üîç –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ '{URLS_DIR}'...")
        for filename in os.listdir(URLS_DIR):
            if filename.endswith('.json'):
                filepath = os.path.join(URLS_DIR, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    category_name = data.get('category_name', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
                    for url in data['product_urls']:
                        # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É
                        async def worker(p_url=url, cat_name=category_name):
                            async with semaphore:
                                await processor.process_product(p_url, cat_name)
                        tasks.append(asyncio.create_task(worker()))

        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(tasks)} —Ç–æ–≤–∞—Ä–æ–≤...")
        await asyncio.gather(*tasks)

    if db_pool:
        await db_pool.close()
        print("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ.")

if __name__ == "__main__":
    asyncio.run(process_details_from_files())